python-dotenv
datasets>=2.18.0
peft>=0.7.1
pip>=24.0
swanlab>=0.3.0
torch==2.10.0
torchvision
flash-attn @ https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.7.16/flash_attn-2.8.3%2Bcu130torch2.10-cp312-cp312-linux_x86_64.whl
transformers>=5.1.0
